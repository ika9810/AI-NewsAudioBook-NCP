# 안티 크롤링

## 간단한 안티 크롤링 회피방법

가장 기본적인 안티 크롤링의 원리를 알아보고 안티 크롤링의 회피방법을 알아보도록 하겠습니다.

![https://gblobscdn.gitbook.com/assets%2F-LdNdL4kaR9zMmPhYDZ8%2F-Lq9UtOzKLVmuGbZKOgf%2F-Lq9YlXCVdJ3iR2KG_e3%2Fimage.png?alt=media&token=90a651b0-6e00-4338-b604-ef5bb4358615](https://gblobscdn.gitbook.com/assets%2F-LdNdL4kaR9zMmPhYDZ8%2F-Lq9UtOzKLVmuGbZKOgf%2F-Lq9YlXCVdJ3iR2KG_e3%2Fimage.png?alt=media&token=90a651b0-6e00-4338-b604-ef5bb4358615)

일반적으로 우리가 일반 웹서비스에 접속해서 데이터를 요청할 때는 웹브라우저(Chrome, Safari, FireFox 등)를 통해서 데이터를 요청하고, 서버는 어디에서 데이터를 요청했는지 확인해서 요청한 데이터를 돌려주는 방식을 사용합니다.

하지만 코드로 만든 데이터수집 프로그램을 통해서 데이터를 요청하는 경우에는 서버가 데이터를 요청한 웹브라우저의 정보를 확인할 수 없기때문에 일부 웹서비스의 경우 요청한 데이터를 돌려주지 않습니다.

이 때 아래와 같은 코드를 수정하면 안티크롤링을 피해갈 수 있습니다.

```python
import requests
from bs4 import BeautifulSoup
raw = requests.get("https://search.naver.com/search.naver?where=news&query=코알라",
                   headers={'User-Agent':'Mozilla/5.0'})
html = BeautifulSoup(raw.text, "html.parser")
```

기존 코드의 requests.get()함수 안에 headers={'User-Agent':'Mozilla/5.0'} 이라는헤더값이 추가된 형태입니다. headers를 통해 서버에 데이터를 요청하면서 웹브라우저에 대한 정보를 같이 전송하여 마치 웹브라우저를 통해 데이터를 요청하는 것처럼 보이게 합니다.

![https://gblobscdn.gitbook.com/assets%2F-LdNdL4kaR9zMmPhYDZ8%2F-Lq9UtOzKLVmuGbZKOgf%2F-Lq9c3w69Tz4o5Ac1Zlv%2Fimage.png?alt=media&token=45e5d7c0-82c9-4ed7-9393-f90ae918fa39](https://gblobscdn.gitbook.com/assets%2F-LdNdL4kaR9zMmPhYDZ8%2F-Lq9UtOzKLVmuGbZKOgf%2F-Lq9c3w69Tz4o5Ac1Zlv%2Fimage.png?alt=media&token=45e5d7c0-82c9-4ed7-9393-f90ae918fa39)

headers를 사용하면 위의 그림처럼 웹브라우저에서 데이터를 요청한 것처럼 서버를 속여 원하는 데이터를 얻을 수 있습니다.

- *실제 User-Agent 값은 훨씬 길지만, 대부분의 경우 "Mozilla/5.0"까지만 적어도 회피할 수 있습니다.(아래는 chrome의 User-Agent 값)*